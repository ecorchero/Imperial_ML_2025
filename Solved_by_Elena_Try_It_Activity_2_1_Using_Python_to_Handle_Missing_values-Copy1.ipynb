{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvmsbE77nXYM"
   },
   "source": [
    "# Self-study try-it activity 2.1 Using Python to handle missing values\n",
    "\n",
    "In data analysis, missing values can be both obstacles to insight and clues to deeper patterns. Like detectives piecing together evidence, data scientists must explore data sets to identify, understand and strategically address these gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOfEmP0XoIWt"
   },
   "source": [
    "## 1. Detecting missing values\n",
    "\n",
    "The first step in handling missing values is to detect them. Letâ€™s explore different methods for identifying missing values in `arrays`, `series` and `DataFrames`. \n",
    "\n",
    "- Boolean masking of missing values using Pandas\n",
    "\n",
    "- Counting missing values\n",
    "\n",
    "- Visualising missing data\n",
    "\n",
    "- Checking missing values in `arrays`\n",
    "\n",
    "- Detecting missing values in `series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBkUwMVgp4dU"
   },
   "source": [
    "Let's explore the first method.\n",
    "\n",
    "### a. Boolean masking of missing values using `Pandas`.\n",
    "\n",
    "The methods `isnull()` and `notnull()` are used to create Boolean masks for missing values. `isnull()` returns `True` for missing values and `False` otherwise, while `notnull()` does the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SdM3zuiRmx0p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame using isnull():\n",
      "       A      B\n",
      "0  False   True\n",
      "1  False  False\n",
      "2   True  False\n",
      "3  False   True\n",
      "\n",
      "DataFrame using notnull():\n",
      "       A      B\n",
      "0   True  False\n",
      "1   True   True\n",
      "2  False   True\n",
      "3   True  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4], 'B': [None, 2, 3, None]})\n",
    "\n",
    "# Detect missing values using isnull() and notnull()\n",
    "print(\"DataFrame using isnull():\")\n",
    "print(df.isnull())\n",
    "print(\"\\nDataFrame using notnull():\")\n",
    "print(df.notnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGg9PPcNqxI2"
   },
   "source": [
    "### b. Counting missing values\n",
    "\n",
    "The missing values in a data set are counted using `.sum()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "apV4GiF3qvgy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing count\n",
      "A    1\n",
      "B    2\n",
      "dtype: int64\n",
      "not missing count\n",
      "A    3\n",
      "B    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' DataFrame from the previous cell is still in memory.\n",
    "# If you restarted the kernel or are running this cell independently,\n",
    "# make sure to run the DataFrame creation cell first:\n",
    "# df = pd.DataFrame({'A': [1, 2, None, 4], 'B': [None, 2, 3, None]})\n",
    "\n",
    "\n",
    "missing_count = df.isnull().sum()\n",
    "not_missing_count = df.notnull().sum()\n",
    "\n",
    "#Compute the missing count\n",
    "print(\"missing count\")\n",
    "print(missing_count)\n",
    "\n",
    "print(\"not missing count\")\n",
    "print(not_missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtNN9RHZrUzp"
   },
   "source": [
    "### c. Visualising missing data\n",
    "\n",
    "Seaborn is a Python library built on top of Matplotlib, designed to simplify the creation of visually appealing and informative statistical graphics. It integrates seamlessly with Pandas' `DataFrames`to support data analysis and visualisation.\n",
    "\n",
    "One useful plot type is the heatmap, a graphical representation where individual values are displayed as colour gradients. Heatmaps are especially helpful for visualising missing data, correlations or any matrix-like data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zMRafTtorFmk",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(df.isnull(), cbar=True, cmap=\"viridis\") # <-- Modify this line\n",
    "plt.show()\n",
    "\n",
    "#Display the heatmap with cbar=True, cmap=\"viridis\". What change do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPJZn_BqQig1"
   },
   "source": [
    "### d. Checking missing values in `arrays`\n",
    "\n",
    "Use NumPyâ€™s `isnan()` function to detect missing values in `arrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w_pDQCmDQSK7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [ 1.  2. nan  4.  5. nan]\n",
      "Presence of NaN values: [False False  True False False  True]\n"
     ]
    }
   ],
   "source": [
    "#declare an array with missing values and display the presence of null values in the array.\n",
    "\n",
    "# Assuming numpy is already imported as np from a previous cell,\n",
    "# but it's good practice to ensure imports are present if running cells independently.\n",
    "import numpy as np\n",
    "\n",
    "# Declare an array with missing values.\n",
    "# np.nan is NumPy's representation for \"Not a Number\", which indicates a missing value.\n",
    "array = np.array([1, 2, np.nan, 4, 5, np.nan])\n",
    "\n",
    "# Display te presence of null values in the array using np.isnan()\n",
    "print(\"Original array:\", array)\n",
    "print(\"Presence of NaN values:\", np.isnan(array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZU6oIiPRb3d"
   },
   "source": [
    "### e. Detecting missing values in `series`\n",
    "\n",
    "Use Pandas' `isna()` function to detect `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uY5YEmueQzCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      " 0    1.0\n",
      "1    NaN\n",
      "2    3.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "\n",
      "Missing values in Series (using isna():\n",
      " 0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "series = None # You can remove or comment out this line as it's immediatly overwritten\n",
    "series = pd.Series([1, None, 3, np.nan])\n",
    "\n",
    "#Display the missing values in the series.\n",
    "print(\"Original Series:\\n\", series)\n",
    "print(\"\\nMissing values in Series (using isna():\\n\", series.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X97-7T88T_2S"
   },
   "source": [
    "## 2. Removing missing values\n",
    "\n",
    "After detecting missing values in Python, one common approach is to remove them, especially when the missing data is minimal or when it cannot be reasonably imputed. \n",
    "\n",
    "The different ways of removal rows and/or column(s) with missing values are:\n",
    "\n",
    "- Removing rows with missing values\n",
    "\n",
    "- Removing columns with missing values\n",
    "\n",
    "- Removing rows or columns based on a threshold\n",
    "\n",
    "- Removing rows where all values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2i7993dRSx6B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n",
      "\n",
      "DataFrame after df.dropna():\n",
      "      A    B    C\n",
      "0  1.0  5.0  9.0\n"
     ]
    }
   ],
   "source": [
    "#Removing rows with missing values. When df.dropna() is used, it removes rows where any column has a missing value.\n",
    "data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C': [9, 10, 11, np.nan]}\n",
    "df = pd.DataFrame(data)\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame after df.dropna():\\n\", df_cleaned)\n",
    "\n",
    "#Explain why df.dropna() results in an empty DataFrame for the given dataset.\n",
    "# How would the outcome change if only one row had no missing values?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IiuKx-GBVuoi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n",
      "\n",
      "DataFrame after df.dropna(axis=1):\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#Removing Columns with Missing Values. If entire columns contain many missing values, they can be dropped using dropna(axis=1).\n",
    "df_cleaned_columns = df.dropna(axis=1) # Specify axis=1 to drop columns\n",
    "\n",
    "#Explain why df.dropna(axis=1) results in a DataFrame with no columns for the given dataset.\n",
    "# How would the outcome change if one column had no missing values?\"\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame after df.dropna(axis=1):\\n\", df_cleaned_columns)\n",
    "\n",
    "# Explain why df.dropna(axis=1) results in a DataFrame with no columns for the given dataset.\n",
    "# How would the outcome change if one column had no missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1y6W0fdDW2RG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n"
     ]
    }
   ],
   "source": [
    "#Removing Rows/Columns Based on Threshold.\n",
    "#The threshold for the minimum number of non-missing values required in a row or column can be specified using the `thresh` parameter.\n",
    "df_cleaned_threshold = df.dropna(axis=0, thresh=2)\n",
    "print(df_cleaned_threshold)\n",
    "#Comment on what happens when `thresh=3`. Give your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "moYHkxwrXWIT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n",
      "\n",
      "DataFrame after df.dropna(how='all'):\n",
      "      A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n"
     ]
    }
   ],
   "source": [
    "#Removing Rows Where All Values Are Missing\n",
    "#To remove rows where all columns are missing, use how='all'.\n",
    "df_cleaned_all = df.dropna(how='all')\n",
    "\n",
    "#\"Explain the difference between using how='any' and how='all' in dropna()\n",
    "#df_cleaned_any = df.dropna(how='any')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame after df.dropna(how='all'):\\n\", df_cleaned_all)\n",
    "\n",
    "# Explain the difference between using how='any' and how='all' in dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cftvkLdEYT5T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with all-NaN column:\n",
      "      A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n",
      "\n",
      "DataFrame after df.dropna(axis=1, how='any'):\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#Removing Columns Where All Values Are Missing.\n",
    "# Columns where all entries are missing can be dropped by setting axis=1 and how='all'\n",
    "df_all_nan_columns_removed = df.dropna(axis=1, how='any')\n",
    "\n",
    "print(\"Original DataFrame with all-NaN column:\\n\", df)\n",
    "print(\"\\nDataFrame after df.dropna(axis=1, how='any'):\\n\", df_all_nan_columns_removed)\n",
    "\n",
    "# Explain the scenarios in which you would use dropna(axis=1, how='all') to remove columns.\n",
    "# Provide examples of when this approach is beneficial for data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPiVwuXzlAfS"
   },
   "source": [
    "## 3. Imputing missing values\n",
    "\n",
    "Imputing missing values involves replacing `NaN` or missing entries in a data set with appropriate values to ensure the data set remains usable for analysis or modelling. Imputing can be done in a variety of ways, such as:\n",
    "\n",
    "- Imputing with the mean or the median\n",
    "\n",
    "- Imputing with the mode\n",
    "\n",
    "- Imputing with the constant value\n",
    "\n",
    "- Imputing with `SimpleImputer`\n",
    "\n",
    "- Forward or backward fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gu2EbhBI1m3S"
   },
   "source": [
    "### a. Imputing with the mean or the median\n",
    "\n",
    "Imputing with the mean is a common technique for numerical data, where the mean of the column replaces missing values. This approach is suitable when the proportion of missing data is small and the mean does not significantly distort the overall distribution.\n",
    "\n",
    "Imputing with the median is a better choice when the data contains outliers that could skew the mean, as the median is less sensitive to extreme values and provides a more robust estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SRWnnMCrjKRS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      A    B      C\n",
      "0  1.0  5.0  156.0\n",
      "1  2.0  NaN  200.0\n",
      "2  NaN  7.0    NaN\n",
      "3  4.0  8.0    5.0\n",
      "\n",
      "DataFrame Imputed with Mean:\n",
      "           A         B           C\n",
      "0  1.000000  5.000000  156.000000\n",
      "1  2.000000  6.666667  200.000000\n",
      "2  2.333333  7.000000  120.333333\n",
      "3  4.000000  8.000000    5.000000\n",
      "\n",
      "DataFrame Imputed with Median:\n",
      "      A    B      C\n",
      "0  1.0  5.0  156.0\n",
      "1  2.0  7.0  200.0\n",
      "2  2.0  7.0  156.0\n",
      "3  4.0  8.0    5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C':[156,200,np.nan,5]})\n",
    "\n",
    "# Impute with the mean\n",
    "df_imputed_mean = df.fillna(df.mean())\n",
    "\n",
    "# Impute with the median\n",
    "df_imputed_median = df.fillna(df.median())\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame Imputed with Mean:\\n\", df_imputed_mean)\n",
    "print(\"\\nDataFrame Imputed with Median:\\n\", df_imputed_median)\n",
    "\n",
    "#Compare the results of using mean() and median() for imputation. How do the imputed values differ, and what might cause these differences?\n",
    "#With the addition of column 'C' containing values [156, 200, np.nan, 5],\n",
    "#Explain why you would prefer to use either mean() or median() for imputation. Consider the impact of outliers on your choice.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IMT2vru6BPI"
   },
   "source": [
    "### b. Imputing with the mode\n",
    "\n",
    "You can use the mode to impute the missing values for categorical data, where the missing values are replaced with the mode (the most frequent value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "k-awiqIb5_WJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Category\n",
      "0        A\n",
      "1        B\n",
      "2      NaN\n",
      "3        A\n",
      "4        C\n",
      "5      NaN\n",
      "\n",
      "DataFrame Imputed with Mode (Series):\n",
      " 0    A\n",
      "1    B\n",
      "2    A\n",
      "3    A\n",
      "4    C\n",
      "5    A\n",
      "Name: Category, dtype: object\n",
      "\n",
      "Original 'A' count: 2\n",
      "New 'A' count: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'Category': ['A', 'B', np.nan, 'A', 'C', np.nan]})\n",
    "\n",
    "# Impute missing values with mode\n",
    "# .mode()[0] is used because .mode() can return a Series if there are multiple modes,\n",
    "# so we pick the first one.\n",
    "df_new = df['Category'].fillna(df['Category'].mode()[0])\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame Imputed with Mode (Series):\\n\", df_new)\n",
    "print(\"\\nOriginal 'A' count:\", df['Category'].value_counts().get('A', 0))\n",
    "print(\"New 'A' count:\", df_new.value_counts().get('A', 0))\n",
    "\n",
    "#Compare the count of 'A' in the original DataFrame and in df_new.\n",
    "#How does imputing missing values with the mode affect the frequency of 'A'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CUzBo48S53"
   },
   "source": [
    "### c. Imputing with the constant value\n",
    "\n",
    "Use this method when you want to assign a default value to indicate the missing data explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "h-iPDt9q7O_0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      A    B\n",
      "0  1.0  5.0\n",
      "1  2.0  NaN\n",
      "2  NaN  7.0\n",
      "3  4.0  8.0\n",
      "\n",
      "DataFrame After Constant Imputation (with -1):\n",
      "      A    B\n",
      "0  1.0  5.0\n",
      "1  2.0 -1.0\n",
      "2 -1.0  7.0\n",
      "3  4.0  8.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]})\n",
    "\n",
    "# Replace NaN in numerical column with a constant value (e.g., -1)\n",
    "df_constant = df.fillna(-1) # This applies -1 to all NaN values in the DataFrame\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame After Constant Imputation (with -1):\\n\", df_constant)\n",
    "\n",
    "#What happens when you replace missing values (NaN) in a numerical column with a constant value like 10?\n",
    "#Compare the original DataFrame and the resulting DataFrame after imputation.\n",
    "#How might this approach affect subsequent data analysis or modeling?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NsHBS4H-i9s"
   },
   "source": [
    "### d. Imputing with `SimpleImputer`\n",
    "\n",
    "`SimpleImputer` is a class in the `scikit-learn` library used to handle missing values in data sets by replacing them with specific imputed values. It provides a systematic way to fill in missing data using strategies like mean, median, most frequent value (mode) or constant value. It works seamlessly with machine learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_a_LrTE79Wuz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0      NaN\n",
      "2   NaN  60000.0\n",
      "3  35.0  65000.0\n",
      "\n",
      "DataFrame After Mean Imputation:\n",
      "     Age        Salary\n",
      "0  25.0  50000.000000\n",
      "1  30.0  58333.333333\n",
      "2  30.0  60000.000000\n",
      "3  35.0  65000.000000\n",
      "\n",
      "DataFrame After Median Imputation:\n",
      "     Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0  60000.0\n",
      "2  30.0  60000.0\n",
      "3  35.0  65000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # Ensure numpy is imported for np.nan\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'Age': [25, 30, np.nan, 35], 'Salary': [50000, np.nan, 60000, 65000]})\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Instantiate SimpleImputer with strategy='mean'\n",
    "imputer_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "\n",
    "# Apply imputation\n",
    "df_imputed_mean = pd.DataFrame(imputer_mean.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(\"\\nDataFrame After Mean Imputation:\\n\", df_imputed_mean)\n",
    "\n",
    "#Use strategy='median' and compare the difference between mean imputer and median imputer\n",
    "imputer_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df_imputed_median = pd.DataFrame(imputer_median.fit_transform(df), columns=df.columns) # Apply to original df\n",
    "\n",
    "print(\"\\nDataFrame After Median Imputation:\\n\", df_imputed_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecuXp1bv_wrU"
   },
   "source": [
    "### e. Predictive imputation\n",
    "\n",
    "Predictive imputation is a common technique for handling missing data in large data sets. Using machine learning models to estimate missing values based on feature relationships ensures data integrity and improves downstream analysis accuracy. However, it requires careful model selection and computational resources to handle large-scale data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RKYyXeWi_aY2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     Age   Salary  Experience\n",
      "0  25.0  50000.0         2.0\n",
      "1  30.0      NaN         5.0\n",
      "2   NaN  60000.0         7.0\n",
      "3  35.0  65000.0         NaN\n",
      "\n",
      "DataFrame After Predictive Imputation (Salary):\n",
      "     Age        Salary  Experience\n",
      "0  25.0  50000.000000         2.0\n",
      "1  30.0  58688.362919         5.0\n",
      "2   NaN  60000.000000         7.0\n",
      "3  35.0  65000.000000         NaN\n",
      "\n",
      "DataFrame After Predictive Imputation (Age column):\n",
      "          Age        Salary  Experience\n",
      "0  25.000000  50000.000000         2.0\n",
      "1  30.000000  58688.362919         5.0\n",
      "2  30.754824  60000.000000         7.0\n",
      "3  35.000000  65000.000000         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a DataFrame with missing values (fresh start for this section)\n",
    "df_original_for_imputation = pd.DataFrame({\n",
    "    'Age': [25, 30, np.nan, 35], \n",
    "    'Salary': [50000, np.nan, 60000, 65000], \n",
    "    'Experience': [2, 5, 7, np.nan]})\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df_original_for_imputation)\n",
    "\n",
    "# --- Original code for Salary imputation (provided in notebook, included for context) ---\n",
    "# Separate rows with and without missing values for the 'Salary' column\n",
    "train_data_salary = df_original_for_imputation[df_original_for_imputation['Salary'].notnull()]\n",
    "test_data_salary = df_original_for_imputation[df_original_for_imputation['Salary'].isnull()]\n",
    "\n",
    "# Train a regression model to predict 'Salary' based on other columns\n",
    "model_salary = LinearRegression()\n",
    "# Fill NaNs in predictors temporarily for the training data\n",
    "X_train_salary = train_data_salary[['Age', 'Experience']].fillna(0)\n",
    "y_train_salary = train_data_salary['Salary']\n",
    "model_salary.fit(X_train_salary, y_train_salary)\n",
    "\n",
    "# Predict missing 'Salary' values\n",
    "X_test_salary = test_data_salary[['Age', 'Experience']].fillna(0)\n",
    "predicted_salary = model_salary.predict(X_test_salary)\n",
    "\n",
    "# Impute the predicted values into the original DataFrame (this modifies df_original_for_imputation)\n",
    "df_original_for_imputation.loc[df_original_for_imputation['Salary'].isnull(), 'Salary'] = predicted_salary\n",
    "print(\"\\nDataFrame After Predictive Imputation (Salary):\\n\", df_original_for_imputation)\n",
    "\n",
    "# --- CORRECTED CODE FOR AGE IMPUTATION (Your Task) ---\n",
    "# Make a fresh copy of the *original* DataFrame to work on for Age imputation, \n",
    "# ensuring it's not affected by potential previous modifications (like the Salary imputation above).\n",
    "df_for_age_imputation = df_original_for_imputation.copy()\n",
    "\n",
    "# 1. Separate rows for training (where 'Age' is NOT null) and testing/prediction (where 'Age' IS null).\n",
    "train_for_age = df_for_age_imputation[df_for_age_imputation['Age'].notnull()]\n",
    "predict_for_age = df_for_age_imputation[df_for_age_imputation['Age'].isnull()]\n",
    "\n",
    "# 2. Define predictors (X) and target (y) for the Age prediction model. Predictors: 'Salary' and 'Experience' Target: 'Age'\n",
    "X_age_train = train_for_age[['Salary', 'Experience']]\n",
    "y_age_train = train_for_age['Age']\n",
    "\n",
    "# IMPORTANT: Handle missing values in the predictors (X_age_train) if necessary, before training the imputation model. \n",
    "# For this small example, let's drop rows with NaNs in X_age_train. \n",
    "# In real-world, you might use SimpleImputer on X_age_train first.\n",
    "X_age_train_cleaned = X_age_train.dropna()\n",
    "y_age_train_cleaned = y_age_train[X_age_train_cleaned.index] # Keep y_age_train aligned with X_age_train_cleaned\n",
    "\n",
    "# 3. Train a Linear Regression model to predict 'Age'.\n",
    "model_age_imputation = LinearRegression()\n",
    "model_age_imputation.fit(X_age_train_cleaned, y_age_train_cleaned)\n",
    "\n",
    "# 4. Prepare data for prediction: Select 'Salary' and 'Experience' from the 'predict_for_age' subset.\n",
    "#    Handle any NaNs in these predictor columns themselves if they exist in the 'predict_for_age' part.\n",
    "#    For example, if Salary/Experience were missing in a row where Age is also missing.\n",
    "X_age_predict = predict_for_age[['Salary', 'Experience']].fillna(0) # Fill NaNs in predictors for consistency if needed\n",
    "\n",
    "# 5. Predict the missing 'Age' values.\n",
    "predicted_ages = model_age_imputation.predict(X_age_predict)\n",
    "\n",
    "# 6. Impute the predicted 'Age' values back into the DataFrame.\n",
    "df_age_imputed_result = df_for_age_imputation.copy() # Make a copy to show final state cleanly\n",
    "df_age_imputed_result.loc[df_age_imputed_result['Age'].isnull(), 'Age'] = predicted_ages\n",
    "\n",
    "print(\"\\nDataFrame After Predictive Imputation (Age column):\\n\", df_age_imputed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:imperialtest]",
   "language": "python",
   "name": "conda-env-imperialtest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
